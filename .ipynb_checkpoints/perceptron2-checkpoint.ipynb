{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import csv\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file credit_data.csv contains the information of people submitting credit card applications. The file credit_label.csv contains the information about wither their applications were approved (1) or denied (-1). \n",
    "(It is noted the values in the data set have been changed by the authors to protect the confidentiality of the data.)\n",
    "\n",
    "We use the Perceptron Learning Algorithm to determine the qualifications that were most heavily considered in the approval/rejection. \n",
    "\n",
    "We will start by splitting the data set into training and testing sets. The first 500 data is for training, and the rest is set aside for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "# https://realpython.com/python-csv/\n",
    "credit_data = np.loadtxt(open(\"credit_data.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "credit_label = np.loadtxt(open(\"credit_label.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "\n",
    "training_data = np.hstack((np.ones((500,1)),credit_data[0:500, :])) # a 500 x 16 matrix\n",
    "training_label = np.vstack(credit_label[0:500])\n",
    "\n",
    "test_data = np.hstack((np.ones((153,1)),credit_data[500:653, :])) # a 153 x 16 matrix\n",
    "test_label = np.vstack(credit_label[500:653])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w_old = 1 x (n+1) initial-guess weight vector\n",
    "\n",
    "data = k x (n+1) matrix. Column 1 contains 1's, Columns 2 through n+1 contain the data\n",
    "\n",
    "label = k x 1 column. 1 for Class 1 (approved), -1 for Class 2 (denied)\n",
    "\n",
    "gamma = learning rate (0<gamma<1)\n",
    "\n",
    "EPOCH = maximum # of cycles through the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Learning Algorithm \n",
    "def w_fit3(w_old, data, label, gamma, EPOCH):\n",
    "    N = np.shape(data)[0]\n",
    "    M = np.zeros((N,1))\n",
    "    c = 0 # counts number of times weight changes\n",
    "    for j in range(EPOCH):\n",
    "        k=0 # stops us once we reach separation of data\n",
    "        for i in range(N):\n",
    "            M[i] = np.sign(w_old @ np.transpose(data[i,:]))\n",
    "            if M[i] != label[i]: # label is incorrect - adjust towards data[i,:]\n",
    "                #print('Adjusting to', data[i,1:3])\n",
    "                w_new = w_old + gamma * (label[i] - M[i]) * data[i,:]\n",
    "                w_old = w_new\n",
    "                #print(\"w_new =\", w_old)\n",
    "                # update counters\n",
    "                k=0\n",
    "                c=c+1\n",
    "            else: # label is correct - no need to adjust w\n",
    "                k=k+1\n",
    "                #print('w_new =', w_old)\n",
    "        if k==N:\n",
    "            #Separation achieved\n",
    "            return w_old\n",
    "        if (k<N and j+1==EPOCH):\n",
    "            #EPOCH attained\n",
    "            return w_old\n",
    "    plt.show()\n",
    "    \n",
    "    #returns a 3x1 weight vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "learning_rate = 0.1\n",
    "EPOCH = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Altering the hyperparameters $\\gamma$ and EPOCH for part (a) and (b) don't seem to make significant differences in the percent error. However, when the random seed isn't set to zero at the beginning of the problem, it effects the Nelder-Mean initial guess and we see a change in the accuracy. Running a few simulations the best $(\\%~error)_{testing}$ on the unseen data that I found for (a) was 18.95, and for (b) 13.73. The worst was (a)33.3, (b)29.4 (these were very mean and rejected a lot of people). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unchanged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nelder-mead weight=  [ 0.16 -0.31 -0.18  0.5  -0.28  0.54  0.08  0.5  -0.03 -0.03  0.13  0.11\n",
      "  0.16  2.15 -0.   -0.  ]\n",
      "perceptron weight=  [  -572.64  -2586.11  -1169.49    884.84  -3397.08  -3396.26   -867.32\n",
      " -12119.3   12800.61 -12447.83  -3450.87   8655.11  -2122.24   2195.75\n",
      "  -1324.4   10229.6 ]\n"
     ]
    }
   ],
   "source": [
    "############## Compute the 'optimal' weight vector ###################\n",
    "\n",
    "np.random.seed(0)\n",
    "w0 = [np.random.uniform(-1, 1) for p in range(0, 16)] # starting weight guess from uniform distribution on -1 to 1\n",
    "#print(w0)\n",
    "\n",
    "# Use Nelder-Mead to find good starting weight\n",
    "# https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html\n",
    "def loss(w):\n",
    "    return (1/500)* np.sum(np.square(np.subtract(w @ training_data.T, training_label)))\n",
    "\n",
    "nmw = minimize(loss, w0, method='nelder-mead',\n",
    "               options={'disp': False})\n",
    "print('nelder-mead weight= ', np.around(nmw.x, decimals = 2))\n",
    "\n",
    "\n",
    "#Perceptron Learning\n",
    "#w1 = w_fit3(w0, training_data, training_label, learning_rate,EPOCH) # using naive starting weight\n",
    "w2 = w_fit3(nmw.x, training_data, training_label, learning_rate,EPOCH) # using Nelder-Mead starting weight\n",
    "print('perceptron weight= ', np.around(w2, decimals = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itâ€™s interesting to note that Nelder-Mead had the highest weights corresponded to citizenship, ethnicity, bank, and amount of debt. \n",
    "\n",
    "Yet after the Perceptron they were employment, prior defaults, ethnicity, and income. \n",
    "\n",
    "This could indicate the Perceptron considers these four factors the most when deciding if an applicant is approved or denied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% training error =  0.352\n",
      "% testing error =  0.3202614379084967 \n",
      " misapproved = 31 \n",
      " misdenied = 18\n"
     ]
    }
   ],
   "source": [
    "############## Use the Perceptron's weight to determine error ###################\n",
    "\n",
    "#how'd it do with training set?\n",
    "self_error = np.count_nonzero((np.transpose([np.sign(w2 @ np.transpose(training_data))])-training_label))/500\n",
    "print(\"% training error = \", self_error)\n",
    "\n",
    "\n",
    "#how'd it do with testing set?\n",
    "unseen_error = np.count_nonzero((np.transpose([np.sign(w2 @ np.transpose(test_data))])-test_label))/153\n",
    "misapproved = sum(1 for x in (np.transpose([np.sign(w2 @ np.transpose(test_data))])-test_label) if x > 0)\n",
    "misdenied = sum(1 for x in (np.transpose([np.sign(w2 @ np.transpose(test_data))])-test_label) if x < 0)\n",
    "print(\"% testing error = \", unseen_error , \"\\n\" ,\"misapproved =\" ,misapproved ,\"\\n\", \"misdenied =\" ,misdenied)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing to see if the calculated weight vector, $w^*$, separates the training data, we will take the hyperplane $(w^*)^T x = 0$ and calculate the amount of points this hyperplane mis-identified. \n",
    "$$\n",
    "(\\%~error)_{training} = \\frac{\\text{# points mis-identified in training set}}{500}\\\\\n",
    "= \\frac{\\text{# nonzero entries of }[(w^* ~training\\_data^T) - training\\_labels^T]}{500}\\\\\n",
    "= 35.2 \\%\n",
    "$$\n",
    "\n",
    "\n",
    "Applying the same concept to the testing data, we find the percent error is \n",
    "$$(\\%~error)_{testing} = \\frac{\\text{# points mis-identified in testing set}}{153}\\\\\n",
    "= \\frac{\\text{# nonzero entries of }[(w^* ~test\\_data^T) - test\\_labels^T]}{153}\\\\\n",
    "\\approx 32.0 \\%\n",
    "$$\n",
    "\n",
    "Surprisingly, the Perceptron will mis-label credit applicants fairly frequently. Counting the number of positive and negative entries of $(w^* ~test\\_data^T) - test\\_labels^T$, we find there were 31 positives and 18 negatives. This implies the Perceptron gave 31 people the Credit Card when it should've been denied, and rejected 18 people who should've been approved. So we might consider this Perceptron to be overly kind and should reject more people. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data normalized by the maximum value of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed Nelder-Mead =  [ 0.51 -0.13  0.17 -0.23 -0.52  0.44 -0.25  0.13 -0.32 -0.17 -0.19 -0.17\n",
      "  0.   -0.04 -0.02 -0.51]\n",
      "normed Perceptron =  [ 2.710e+00 -4.300e-01 -5.500e-01 -1.070e+00  1.000e-02  9.700e-01\n",
      " -2.900e-01  5.500e-01  1.920e+00 -2.370e+00 -1.290e+00 -3.300e-01\n",
      " -5.000e-01 -1.100e-01 -1.180e+00  1.366e+01]\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "norm = np.amax(training_data[0:500,1:16],axis=0)\n",
    "\n",
    "# split data into training & testing sets\n",
    "norm_training = np.zeros((500,16))\n",
    "norm_test = np.zeros((153,16))\n",
    "for j in range(1,16):\n",
    "    for i in range(500):\n",
    "        norm_training[i,0] = 1\n",
    "        norm_training[i,j] = training_data[i,j]/norm[j-1]\n",
    "    for k in range(153):\n",
    "        norm_test[k,0] = 1\n",
    "        norm_test[k,j] = test_data[k,j]/norm[j-1]\n",
    "\n",
    "# Nelder-Mead\n",
    "def norm_loss(w):\n",
    "    return (1/500)* np.sum(np.square(np.subtract(w @ norm_training.T, training_label)))\n",
    "\n",
    "norm_nmw = minimize(norm_loss, w0, method='nelder-mead',\n",
    "               options={'disp': False})\n",
    "print('normed Nelder-Mead = ', np.around(norm_nmw.x,decimals = 2))\n",
    "\n",
    "\n",
    "#Perceptron Algorithm\n",
    "#w1n = w_fit3(w0, norm_training, training_label, learning_rate,EPOCH) # using naive starting vector\n",
    "w2n = w_fit3(norm_nmw.x, norm_training, training_label, learning_rate,EPOCH) # using Nelder-mead starting vector\n",
    "print('normed Perceptron = ', np.around(w2n, decimals = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factors most influencing the approval or rejection in the Perceptron are the applicant's income, prior defaults, eployment status, and years of employment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% training error =  0.236\n",
      "% testing error =  0.1830065359477124 \n",
      " misapproved = 4 \n",
      " misdenied = 24\n"
     ]
    }
   ],
   "source": [
    "############## Use the Perceptron's weight to determine error ###################\n",
    "\n",
    "# on itself\n",
    "norm_self_error = np.count_nonzero((np.transpose([np.sign(w2n @ np.transpose(norm_training))])-training_label))/500\n",
    "print(\"% training error = \",norm_self_error)\n",
    "\n",
    "# on unseen data        \n",
    "norm_unseen_error = np.count_nonzero((np.transpose([np.sign(w2n @ np.transpose(norm_test))])-test_label))/153\n",
    "misapproved = sum(1 for x in (np.transpose([np.sign(w2n @ np.transpose(norm_test))])-test_label) if x > 0)\n",
    "misdenied = sum(1 for x in (np.transpose([np.sign(w2n @ np.transpose(norm_test))])-test_label) if x < 0)\n",
    "print(\"% testing error = \", norm_unseen_error , \"\\n\" ,\"misapproved =\" ,misapproved ,\"\\n\", \"misdenied =\" ,misdenied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing how well this Perceptron's hyperplane, $\\tilde{w}^T x = 0$, categorizes the data,\n",
    "$$\n",
    "(\\%~error)_{training} = \\frac{\\text{# points mis-identified in training set}}{500} = 23.6 \\%\\\\\n",
    "(\\%~error)_{testing} = \\frac{\\text{# points mis-identified in testing set}}{153} \\approx 18.3 \\%\n",
    "$$\n",
    "Upon further investigation, we find that this normalized Perceptron gave 4 people approval when it shouldn't have, but it denied 24 people who the banker approved. Thus, the normalized Perceptron is in general more accurate, but also more strict than the un-normalized version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
